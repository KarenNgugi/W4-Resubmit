{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JEVoPo-MN53s"
   },
   "source": [
    "# <font color='green'> 1. Introduction </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M6mAjM12OM9z"
   },
   "source": [
    "We will work as a Data Scientist for the Autolib electric car-sharing service company to investigate a claim about the blue cars from the provided Autolib dataset.\n",
    "\n",
    "In an effort to do this, we need to identify some areas and periods of interest via sampling stating the reason to the choice of method, then perform hypothesis testing with regards to the claim that we will have made.\n",
    "\n",
    "To work on this project, we will perform the following analysis with Python:\n",
    "\n",
    "  1. Find and deal with outliers, anomalies, and missing data within the dataset.\n",
    "  2. Plot appropriate univariate and bivariate summaries recording our observations.\n",
    "  3. Implement the solution by performing hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ChVUkJSNPkfQ"
   },
   "source": [
    "# <font color='green'> 2. Problem Statement </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Introduce the data you will be describing and the random variable that you are investigating. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set I am working with is the Autolib dataset that is produced on the Moringa School LMS. It contains information concerning 3 brands of electric cars belonging to the Autolib company: the Bluecar, the Utilib, and the Utilib 14. The random variable I will be investigating is the mean number of Utilib 14 cars taken, specifically whether it is greater than that of the Utilib cars, indicating its popularity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fsXte5fQ9bka"
   },
   "outputs": [],
   "source": [
    "# load libraries to be used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "XyUeebFNQMpS",
    "outputId": "099723fe-ca58-4c9c-8692-34eafe03aa8f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postal code</th>\n",
       "      <th>date</th>\n",
       "      <th>n_daily_data_points</th>\n",
       "      <th>dayOfWeek</th>\n",
       "      <th>day_type</th>\n",
       "      <th>BlueCars_taken_sum</th>\n",
       "      <th>BlueCars_returned_sum</th>\n",
       "      <th>Utilib_taken_sum</th>\n",
       "      <th>Utilib_returned_sum</th>\n",
       "      <th>Utilib_14_taken_sum</th>\n",
       "      <th>Utilib_14_returned_sum</th>\n",
       "      <th>Slots_freed_sum</th>\n",
       "      <th>Slots_taken_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75001</td>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>weekday</td>\n",
       "      <td>110</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75001</td>\n",
       "      <td>1/2/2018</td>\n",
       "      <td>1438</td>\n",
       "      <td>1</td>\n",
       "      <td>weekday</td>\n",
       "      <td>98</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75001</td>\n",
       "      <td>1/3/2018</td>\n",
       "      <td>1439</td>\n",
       "      <td>2</td>\n",
       "      <td>weekday</td>\n",
       "      <td>138</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75001</td>\n",
       "      <td>1/4/2018</td>\n",
       "      <td>1320</td>\n",
       "      <td>3</td>\n",
       "      <td>weekday</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75001</td>\n",
       "      <td>1/5/2018</td>\n",
       "      <td>1440</td>\n",
       "      <td>4</td>\n",
       "      <td>weekday</td>\n",
       "      <td>114</td>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Postal code      date  n_daily_data_points  dayOfWeek day_type  \\\n",
       "0        75001  1/1/2018                 1440          0  weekday   \n",
       "1        75001  1/2/2018                 1438          1  weekday   \n",
       "2        75001  1/3/2018                 1439          2  weekday   \n",
       "3        75001  1/4/2018                 1320          3  weekday   \n",
       "4        75001  1/5/2018                 1440          4  weekday   \n",
       "\n",
       "   BlueCars_taken_sum  BlueCars_returned_sum  Utilib_taken_sum  \\\n",
       "0                 110                    103                 3   \n",
       "1                  98                     94                 1   \n",
       "2                 138                    139                 0   \n",
       "3                 104                    104                 2   \n",
       "4                 114                    117                 3   \n",
       "\n",
       "   Utilib_returned_sum  Utilib_14_taken_sum  Utilib_14_returned_sum  \\\n",
       "0                    2                   10                       9   \n",
       "1                    1                    8                       8   \n",
       "2                    0                    2                       2   \n",
       "3                    2                    9                       8   \n",
       "4                    3                    6                       6   \n",
       "\n",
       "   Slots_freed_sum  Slots_taken_sum  \n",
       "0               22               20  \n",
       "1               23               22  \n",
       "2               27               27  \n",
       "3               25               21  \n",
       "4               18               20  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autolib = pd.read_csv('autolib_daily_events_postal_code.csv')\n",
    "autolib.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>State very precisely the null and alternate hypothesis that you will be testing.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis I will test is that the mean of the number of Utilib 14 cars taken is equal to that of the Utilib cars, i.e., there is no difference between the two means. The alternate hypothesis is that the mean of the Utilib 14 cars taken is not equal to that of the Utilib cars.\n",
    "\n",
    "In short: \n",
    "    * H0: μ Utilib 14 = μ Utilib\n",
    "    * H1: μ Utilib 14 ≠ μ Utilib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Provide some explanation for why this hypothesis is important and/or interesting.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason I find it important to investigate this is because, from what I’ve seen, BlueCars are easily the most popular cars, leaving both the Utilib and the Utilib 14 in the dust, and it is now a matter of investigating which of these two is the next popular one. If Autolib wishes to do away with the least popular one or order more cars, this hypothesis testing will prove to be useful in helping them make a beneficial decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green'>3. Data Description</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Provide information about the data necessary to understand the rest of the report including a precise statement of the random variable.</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains such information as:\n",
    "* Postal code: postal code of the area (in Paris)\n",
    "* Date: the date of the time the data was collected\n",
    "* The number of daily data points: the number of daily data points that were available for aggregation that day\n",
    "* The day of the week\n",
    "* The type of the day, i.e., was it a weekend or a weekday?\n",
    "* The total number of Bluecars taken that day in that area\n",
    "* The total number of Bluecars returned that day in that area\n",
    "* The total number of Utilibs taken that day in that area\n",
    "* The total number of Utilibs returned that day in that area\n",
    "* The total number of Utilib 14s taken that day in that area\n",
    "* The total number of Utilib 14s returned that day in that area\n",
    "* The total number of recharging slots released that day in that area\n",
    "* The total number of recharging slots taken that day in that area\n",
    "\n",
    "The variable I will work on is the total number of Utilib 14s taken that day in that area, i.e., the 'Utilib_14_taken_sum' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "colab_type": "code",
    "id": "kyDRXRLuQa6E",
    "outputId": "24d0d440-5aa3-4b62-917c-8645f439be1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column name</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Postal code</td>\n",
       "      <td>postal code of the area (in Paris)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>date</td>\n",
       "      <td>date of the row aggregation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n_daily_data_points</td>\n",
       "      <td>number of daily data poinst that were availabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dayOfWeek</td>\n",
       "      <td>identifier of weekday (0: Monday -&gt; 6: Sunday)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>day_type</td>\n",
       "      <td>weekday or weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BlueCars_taken_sum</td>\n",
       "      <td>Number of bluecars taken that date in that area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BlueCars_returned_sum</td>\n",
       "      <td>Number of bluecars returned that date in that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Utilib_taken_sum</td>\n",
       "      <td>Number of Utilib taken that date in that area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Utilib_returned_sum</td>\n",
       "      <td>Number of Utilib returned that date in that area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Utilib_14_taken_sum</td>\n",
       "      <td>Number of Utilib 1.4 taken that date in that area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Utilib_14_returned_sum</td>\n",
       "      <td>Number of Utilib 1.4 returned that date in tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Slots_freed_sum</td>\n",
       "      <td>Number of recharging slots released that date ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Slots_taken_sum</td>\n",
       "      <td>Number of rechargign slots taken that date in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Column name                                        explanation\n",
       "0              Postal code                 postal code of the area (in Paris)\n",
       "1                     date                        date of the row aggregation\n",
       "2      n_daily_data_points  number of daily data poinst that were availabl...\n",
       "3                dayOfWeek     identifier of weekday (0: Monday -> 6: Sunday)\n",
       "4                 day_type                                 weekday or weekend\n",
       "5       BlueCars_taken_sum    Number of bluecars taken that date in that area\n",
       "6    BlueCars_returned_sum  Number of bluecars returned that date in that ...\n",
       "7         Utilib_taken_sum      Number of Utilib taken that date in that area\n",
       "8      Utilib_returned_sum   Number of Utilib returned that date in that area\n",
       "9      Utilib_14_taken_sum  Number of Utilib 1.4 taken that date in that area\n",
       "10  Utilib_14_returned_sum  Number of Utilib 1.4 returned that date in tha...\n",
       "11         Slots_freed_sum  Number of recharging slots released that date ...\n",
       "12         Slots_taken_sum  Number of rechargign slots taken that date in ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# provide variable definitions\n",
    "varDef = pd.read_excel('columns_explanation.xlsx')\n",
    "varDef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Provide a description of the source of your data and the data collection procedures, the descriptive statistics, and some assertions about the model that is consistent with the data. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set was obtained from the Moringa School LMS platform (no idea where they got it, so I cannot provide any information on the data collection procedures).\n",
    "\n",
    "As seen from the summary statistics below, there are 16,085 records and 13 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16085, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postal code</th>\n",
       "      <th>date</th>\n",
       "      <th>n_daily_data_points</th>\n",
       "      <th>dayOfWeek</th>\n",
       "      <th>day_type</th>\n",
       "      <th>BlueCars_taken_sum</th>\n",
       "      <th>BlueCars_returned_sum</th>\n",
       "      <th>Utilib_taken_sum</th>\n",
       "      <th>Utilib_returned_sum</th>\n",
       "      <th>Utilib_14_taken_sum</th>\n",
       "      <th>Utilib_14_returned_sum</th>\n",
       "      <th>Slots_freed_sum</th>\n",
       "      <th>Slots_taken_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16085.000000</td>\n",
       "      <td>16085</td>\n",
       "      <td>16085.000000</td>\n",
       "      <td>16085.000000</td>\n",
       "      <td>16085</td>\n",
       "      <td>16085.000000</td>\n",
       "      <td>16085.000000</td>\n",
       "      <td>16085.000000</td>\n",
       "      <td>16085.000000</td>\n",
       "      <td>16085.000000</td>\n",
       "      <td>16085.000000</td>\n",
       "      <td>16085.000000</td>\n",
       "      <td>16085.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2/23/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>weekday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>88791.293876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1431.330619</td>\n",
       "      <td>2.969599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.926951</td>\n",
       "      <td>125.912714</td>\n",
       "      <td>3.698290</td>\n",
       "      <td>3.699099</td>\n",
       "      <td>8.600560</td>\n",
       "      <td>8.599192</td>\n",
       "      <td>22.629033</td>\n",
       "      <td>22.629282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7647.342000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.212050</td>\n",
       "      <td>2.008378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>185.426579</td>\n",
       "      <td>185.501535</td>\n",
       "      <td>5.815058</td>\n",
       "      <td>5.824634</td>\n",
       "      <td>12.870098</td>\n",
       "      <td>12.868993</td>\n",
       "      <td>52.120263</td>\n",
       "      <td>52.146030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>75001.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1174.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>91330.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1439.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>92340.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>93400.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95880.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>359.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Postal code       date  n_daily_data_points     dayOfWeek day_type  \\\n",
       "count   16085.000000      16085         16085.000000  16085.000000    16085   \n",
       "unique           NaN        156                  NaN           NaN        2   \n",
       "top              NaN  2/23/2018                  NaN           NaN  weekday   \n",
       "freq             NaN        104                  NaN           NaN    11544   \n",
       "mean    88791.293876        NaN          1431.330619      2.969599      NaN   \n",
       "std      7647.342000        NaN            33.212050      2.008378      NaN   \n",
       "min     75001.000000        NaN          1174.000000      0.000000      NaN   \n",
       "25%     91330.000000        NaN          1439.000000      1.000000      NaN   \n",
       "50%     92340.000000        NaN          1440.000000      3.000000      NaN   \n",
       "75%     93400.000000        NaN          1440.000000      5.000000      NaN   \n",
       "max     95880.000000        NaN          1440.000000      6.000000      NaN   \n",
       "\n",
       "        BlueCars_taken_sum  BlueCars_returned_sum  Utilib_taken_sum  \\\n",
       "count         16085.000000           16085.000000      16085.000000   \n",
       "unique                 NaN                    NaN               NaN   \n",
       "top                    NaN                    NaN               NaN   \n",
       "freq                   NaN                    NaN               NaN   \n",
       "mean            125.926951             125.912714          3.698290   \n",
       "std             185.426579             185.501535          5.815058   \n",
       "min               0.000000               0.000000          0.000000   \n",
       "25%              20.000000              20.000000          0.000000   \n",
       "50%              46.000000              46.000000          1.000000   \n",
       "75%             135.000000             135.000000          4.000000   \n",
       "max            1352.000000            1332.000000         54.000000   \n",
       "\n",
       "        Utilib_returned_sum  Utilib_14_taken_sum  Utilib_14_returned_sum  \\\n",
       "count          16085.000000         16085.000000            16085.000000   \n",
       "unique                  NaN                  NaN                     NaN   \n",
       "top                     NaN                  NaN                     NaN   \n",
       "freq                    NaN                  NaN                     NaN   \n",
       "mean               3.699099             8.600560                8.599192   \n",
       "std                5.824634            12.870098               12.868993   \n",
       "min                0.000000             0.000000                0.000000   \n",
       "25%                0.000000             1.000000                1.000000   \n",
       "50%                1.000000             3.000000                3.000000   \n",
       "75%                4.000000            10.000000               10.000000   \n",
       "max               58.000000           100.000000              101.000000   \n",
       "\n",
       "        Slots_freed_sum  Slots_taken_sum  \n",
       "count      16085.000000     16085.000000  \n",
       "unique              NaN              NaN  \n",
       "top                 NaN              NaN  \n",
       "freq                NaN              NaN  \n",
       "mean          22.629033        22.629282  \n",
       "std           52.120263        52.146030  \n",
       "min            0.000000         0.000000  \n",
       "25%            0.000000         0.000000  \n",
       "50%            0.000000         0.000000  \n",
       "75%            5.000000         5.000000  \n",
       "max          360.000000       359.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(autolib.shape)\n",
    "autolib.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green'>4. Hypothesis Testing Procedure </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Present the details concerning how you will test your hypothesis. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do after preparing and cleaning the dataset would be to collect only records taken on a weekend since that is where my focus is. After creating a separate data set containing weekend-only records, which will act as the population, I will randomly select 10% of its data points to be my sample data. I'm assuming the sample size will be greater than 30, hence a z-test will be ideal. However, should I find that my sample size is less than 30, then I will resort to using a t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green'>5. Data Cleaning </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['postal_code', 'date', 'daily_data_points', 'day_of_week', 'day_type',\n",
       "       'bluecars_taken', 'bluecars_returned', 'utilib_taken',\n",
       "       'utilib_returned', 'utilib_14_taken', 'utilib_14_returned',\n",
       "       'slots_freed', 'slots_taken'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change column names to improve consistency and readability\n",
    "\n",
    "autolib = autolib.rename(columns = {\n",
    "    'Postal code' : 'postal_code',\n",
    "    'n_daily_data_points' : 'daily_data_points',\n",
    "    'dayOfWeek' : 'day_of_week',\n",
    "    'BlueCars_taken_sum' : 'bluecars_taken',\n",
    "    'BlueCars_returned_sum' : 'bluecars_returned',\n",
    "    'Utilib_taken_sum' : 'utilib_taken',\n",
    "    'Utilib_returned_sum' : 'utilib_returned',\n",
    "    'Utilib_14_taken_sum' : 'utilib_14_taken',\n",
    "    'Utilib_14_returned_sum' : 'utilib_14_returned',\n",
    "    'Slots_freed_sum' : 'slots_freed',\n",
    "    'Slots_taken_sum' : 'slots_taken'\n",
    "})\n",
    "\n",
    "autolib.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_data_points</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_type</th>\n",
       "      <th>bluecars_taken</th>\n",
       "      <th>bluecars_returned</th>\n",
       "      <th>utilib_taken</th>\n",
       "      <th>utilib_returned</th>\n",
       "      <th>utilib_14_taken</th>\n",
       "      <th>utilib_14_returned</th>\n",
       "      <th>slots_freed</th>\n",
       "      <th>slots_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [postal_code, date, daily_data_points, day_of_week, day_type, bluecars_taken, bluecars_returned, utilib_taken, utilib_returned, utilib_14_taken, utilib_14_returned, slots_freed, slots_taken]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for and display duplicates\n",
    "duplicatedData = autolib[autolib.duplicated()]\n",
    "duplicatedData\n",
    "\n",
    "## no duplicated data found so no need to drop any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of missing values\n",
    "np.count_nonzero(autolib.isna())\n",
    "\n",
    "## no missing values so there is no need of dropping or imputing any records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9783, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove outliers if any are present using the interquartile range\n",
    "Q1 = autolib.quantile(0.25)\n",
    "Q3 = autolib.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "autolib = autolib[~((autolib < (Q1 - 1.5 * IQR)) |(autolib > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "autolib.shape\n",
    "\n",
    "## we are now down to 5319 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_igpF-47R5p0",
    "outputId": "bdf61487-3116-4408-f040-70c2497784e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['weekend'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since I am interested in only the data that is on a weekend, I will create a dataset\n",
    "# containing only weekend entries\n",
    "\n",
    "weekend = autolib.loc[autolib['day_type'] == 'weekend']\n",
    "\n",
    "# confirm that it has only weekends\n",
    "weekend.day_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKg6xa2nSrkK"
   },
   "outputs": [],
   "source": [
    "# delete 'day_type' column since it is unnecessary\n",
    "weekend = weekend.drop(columns=['day_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-jCbo-eXhlu9",
    "outputId": "43edf36f-6851-4a81-a1e9-d827067d2c94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2963, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of data set\n",
    "weekend.shape\n",
    "\n",
    "## further down to 1,820 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>daily_data_points</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>bluecars_taken</th>\n",
       "      <th>bluecars_returned</th>\n",
       "      <th>utilib_taken</th>\n",
       "      <th>utilib_returned</th>\n",
       "      <th>utilib_14_taken</th>\n",
       "      <th>utilib_14_returned</th>\n",
       "      <th>slots_freed</th>\n",
       "      <th>slots_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2963.000000</td>\n",
       "      <td>2963.000000</td>\n",
       "      <td>2963.000000</td>\n",
       "      <td>2963.000000</td>\n",
       "      <td>2963.000000</td>\n",
       "      <td>2963.000000</td>\n",
       "      <td>2963.000000</td>\n",
       "      <td>2963.000000</td>\n",
       "      <td>2963.000000</td>\n",
       "      <td>2963.000000</td>\n",
       "      <td>2963.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>93112.126223</td>\n",
       "      <td>1439.825177</td>\n",
       "      <td>5.527843</td>\n",
       "      <td>57.718529</td>\n",
       "      <td>57.354708</td>\n",
       "      <td>1.742153</td>\n",
       "      <td>1.734391</td>\n",
       "      <td>4.143098</td>\n",
       "      <td>4.129261</td>\n",
       "      <td>0.768815</td>\n",
       "      <td>0.748228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1015.852872</td>\n",
       "      <td>0.493524</td>\n",
       "      <td>0.499308</td>\n",
       "      <td>48.991550</td>\n",
       "      <td>49.600634</td>\n",
       "      <td>2.063558</td>\n",
       "      <td>2.080906</td>\n",
       "      <td>4.132647</td>\n",
       "      <td>4.197661</td>\n",
       "      <td>2.029545</td>\n",
       "      <td>1.990200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>91330.000000</td>\n",
       "      <td>1438.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>92270.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>93110.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>94100.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95880.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        postal_code  daily_data_points  day_of_week  bluecars_taken  \\\n",
       "count   2963.000000        2963.000000  2963.000000     2963.000000   \n",
       "mean   93112.126223        1439.825177     5.527843       57.718529   \n",
       "std     1015.852872           0.493524     0.499308       48.991550   \n",
       "min    91330.000000        1438.000000     5.000000        0.000000   \n",
       "25%    92270.000000        1440.000000     5.000000       21.000000   \n",
       "50%    93110.000000        1440.000000     6.000000       43.000000   \n",
       "75%    94100.000000        1440.000000     6.000000       82.000000   \n",
       "max    95880.000000        1440.000000     6.000000      293.000000   \n",
       "\n",
       "       bluecars_returned  utilib_taken  utilib_returned  utilib_14_taken  \\\n",
       "count        2963.000000   2963.000000      2963.000000      2963.000000   \n",
       "mean           57.354708      1.742153         1.734391         4.143098   \n",
       "std            49.600634      2.063558         2.080906         4.132647   \n",
       "min             0.000000      0.000000         0.000000         0.000000   \n",
       "25%            20.000000      0.000000         0.000000         1.000000   \n",
       "50%            42.000000      1.000000         1.000000         3.000000   \n",
       "75%            82.000000      3.000000         3.000000         6.000000   \n",
       "max           301.000000     10.000000        10.000000        22.000000   \n",
       "\n",
       "       utilib_14_returned  slots_freed  slots_taken  \n",
       "count         2963.000000  2963.000000  2963.000000  \n",
       "mean             4.129261     0.768815     0.748228  \n",
       "std              4.197661     2.029545     1.990200  \n",
       "min              0.000000     0.000000     0.000000  \n",
       "25%              1.000000     0.000000     0.000000  \n",
       "50%              3.000000     0.000000     0.000000  \n",
       "75%              6.000000     0.000000     0.000000  \n",
       "max             22.000000    12.000000    12.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary statistics of weekend dataset\n",
    "weekend.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Describe the logic behind your null and alternate hypotheses: where did they come from and why are they interesting.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason I decided to look into which is more popular between the Utilib and the Utilib 14 is because, according to the summary statistics, their means are very low compared to that of the Bluecar, so I want to see if there is sufficient evidence that the Utilib 14 is more popular than the Utilib. Personally, the '14' in 'Utilib 14' appeals to me because it seems to indicate that it is the 14th new and improved version of the Utilib, and I would like to see whether it is indeed better than its originator. Additionally, as a Data Scienctist working for Autolib, I figure I might be asked to determine which of the two is the least popular in case they want to do away with it and invest in a more profitable brand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Describe the test statistic you will use (i.e., z, t, f) and why. Have you satisfied the assumptions necessary for using the specific statistic?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I am working with a very large dataset, where the sample size will be greater than 30, I will use a z-test. All assumptions are satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Determine the alpha level you will use.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alpha level I will use is 0.05 (confidence level of 95%) because it is the standard alpha level used, and I see no particular reason to use the other alpha levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SlQ4VCHzP5RX"
   },
   "source": [
    "# <font color='green'> 6. Hypothesis Testing </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TB_gpqvUV_Oy"
   },
   "source": [
    "#### <font color='blue'> 6.1 Hypothesis Statement Formulation </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dEQ1yz5fe5V0"
   },
   "source": [
    "The null hypothesis is that there is no difference in the mean of the Utilib 14 taken and that of the Utilib.\n",
    "\n",
    "The alternative hypothesis states that there is a difference in the mean of the two.\n",
    "\n",
    "Simply put:\n",
    "\n",
    "\n",
    "*   H0 : μ of Utilib 14 = μ of Utilib\n",
    "*   H1 : μ of Utilib 14 ≠ μ of Utilib\n",
    "\n",
    "We will use a confidence level of 95%, that is, an alpha level of 0.05 to determine whether or not to reject the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MHm8lNK0Yvzu"
   },
   "source": [
    "#### <font color='blue'> 6.2 Hypothesis Testing Computation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "EY0Utlqyngw2",
    "outputId": "68b04f25-e3f9-4ab3-93cb-07a2fa1236ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size is 296\n",
      "       postal_code       date  daily_data_points  day_of_week  bluecars_taken  \\\n",
      "15458        94700  6/17/2018               1440            6              56   \n",
      "13935        94150   2/3/2018               1438            5              23   \n",
      "15399        94700   4/8/2018               1440            6              42   \n",
      "15682        95100  3/10/2018               1440            5              22   \n",
      "9770         92700  4/29/2018               1440            6             237   \n",
      "\n",
      "       bluecars_returned  utilib_taken  utilib_returned  utilib_14_taken  \\\n",
      "15458                 63             0                0                5   \n",
      "13935                 31             0                0                1   \n",
      "15399                 41             0                0                3   \n",
      "15682                 30             0                0                0   \n",
      "9770                 244             2                2               11   \n",
      "\n",
      "       utilib_14_returned  slots_freed  slots_taken  \n",
      "15458                   5            0            0  \n",
      "13935                   1            0            1  \n",
      "15399                   3            0            0  \n",
      "15682                   0            0            0  \n",
      "9770                   13            0            0  \n"
     ]
    }
   ],
   "source": [
    "# we will use a simple random sampling to randomly select 10% of values from the population\n",
    "# which is the weekend dataset\n",
    "\n",
    "popSize = weekend.shape[0]\n",
    "sampleSize = int(0.1 * popSize)\n",
    "print(\"Sample size is\", sampleSize)\n",
    "## since the sample size is greater than 30, we will use z test\n",
    "\n",
    "sampleData = weekend.sample(n = sampleSize, replace = 'False')\n",
    "print(sampleData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Cp3F2dGKk4iL",
    "outputId": "b1905e45-fecb-4003-d12a-cdb50435b3ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic is -0.6580670507867209\n"
     ]
    }
   ],
   "source": [
    "# manually calculate the z-test statistic using the population mean, population standard deviation,\n",
    "# sample mean, and sample size\n",
    "from math import sqrt\n",
    "popMean = weekend.utilib_14_taken.mean()\n",
    "popStd = weekend.utilib_14_taken.std()\n",
    "sampleMean = sampleData.utilib_14_taken.mean()\n",
    "n = 266\n",
    "alpha = 0.05\n",
    "\n",
    "statistic = (sampleMean - popMean) / (popStd / sqrt(n))\n",
    "print(\"Test statistic is\", statistic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kdLW3ze1t3R7",
    "outputId": "9702e577-f2c3-4a8c-d82e-5b423ef1b2cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5104950470153276"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the p value\n",
    "p_value = stats.norm.sf(abs(statistic))*2\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UH_ui9TNYzzZ"
   },
   "source": [
    "#### <font color='blue'> 6.3 Hypothesis Testing Interpretation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Pyl_9QleYuOS",
    "outputId": "4660711a-ffa2-4d82-c90b-132c3c3c117e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null hypothesis failed to be rejected.\n"
     ]
    }
   ],
   "source": [
    "if p_value <= alpha:\n",
    "  print(\"Null hypothesis rejected.\")\n",
    "if p_value > alpha:\n",
    "  print(\"Null hypothesis failed to be rejected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green'> 7. Hypothesis Testing Results and Conclusion </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the data set and removing outliers and then slicing it so as to work with only those that are taken on weekends, I was left with 1820 records. 10% of this gave exactly 182 records which I used for my sample.\n",
    "\n",
    "The z-test using the population mean, population standard deviation, sample mean, and sample size resulted in a z statistic of approximately -2.5865 which generated a p-value of approximately 0.00969. Since this p-value is less than our pre-set alpha value of 0.05, it means that we have sufficient evidence to reject our null hypothesis which states that the mean of the Utilib 14 cars is equal to that of the Utilib. In other words, we now accept that there is no significant difference between the means of the two brands, i.e., neither is better than the other. So Autolib can do away with one of them without worrying about incurring great losses since they are both equally popular."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Karen W4 Resubmit",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
